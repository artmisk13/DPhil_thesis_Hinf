# Command used in Chapter 4 for stand-alone bioinformatic tools: Identifying variants associated with NTHi through GWAS

## 1) NCBI SRA to assembly pipeline, using:
## 	- SPAdes: https://github.com/ablab/spades
##	- SRA-Toolkit: https://github.com/ncbi/sra-tools
## Pipeline was run through the University of Oxford ARC computer cluster

module load SRA-Toolkit/3.0.3-gompi-2022a
module load SPAdes/3.15.2-GCC-10.2.0

OUTDIR="/dir/for/fasta_output"
CHDIR="/working/dir" 	# this directory should contain 3 subdirs "batch", "accession_files", "fastq"
						# "batch" subdir contains textfiles, named in numerical order, e.g. 1.txt, 2.txt, etc.,
							# and each contains list of accession numbers
							# (I used 10 accessions/file to optimise computer cluster processing speed and fastq reads temp storage)
						# "accession_files" and "fastq" subdirs for intermediate output files

for i in {1..100}; do # range depends how many batches of text files
	mkdir ${CHDIR}/accession_files/${i};
	mkdir ${CHDIR}/fastq/${i};
	mkdir ${OUTDIR}/${i};
	for f in $(cat ${CHDIR}/batch/${i}.txt); do
		prefetch $f -O ${CHDIR}/accession_files/${i};
		fasterq-dump ${CHDIR}/accession_files/${i}/$f -O ${CHDIR}/fastq/${i} -e 16;
		spades.py -k 31,43,55,77 --isolate --disable-gzip-output --pe1-1 ${CHDIR}/fastq/${i}/${f}_1.fastq \
			--pe1-2 ${CHDIR}/fastq/${i}/${f}_2.fastq -o ${OUTDIR}/${i}/$f --threads 48;
	done;
	rm -r ${CHDIR}/fastq/${i};
done

### --- ###


## 2) QUAST: https://github.com/ablab/quast
## Program was run through the University of Oxford ARC computer cluster

module load QUAST/5.0.2-foss-2020a-Python-3.8.2

INDIR="/dir/to/fasta/files"
OUTDIR="/dir/for/quast_output"

for f in $(cat ./fasta.txt); do # fasta.txt contains list of fasta file names
	quast.py ${INDIR}/$f -o ${OUTDIR}/$f;
done

### --- ###


## 3) Prokka: https://github.com/tseemann/prokka
## Program was run through the University of Oxford ARC computer cluster, in a personal conda environment

OUTDIR="/dir/to/prokka_output"

for f in $(cat /dir/to/fasta_file_list.txt); do
    prokka --outdir ${OUTDIR} --cpus 48 --compliant \
    --force --prefix ${f} /dir/to/fasta/$f;
done

### --- ###


## 4) PIRATE: https://github.com/SionBayliss/PIRATE
## Program was run through the University of Oxford ARC computer cluster

module load PIRATE/1.0.5

GFF="/dir/to/prokka_output/gffs_only" # directory containing all annotated genomes as GFF files
OUTDIR="/dir/to/pirate_output"

PIRATE -i ${GFF} -o ${OUTDIR} -a -r -t 24

## Result: 	"modified_gff" containing modified GFF files based on orthologous clustering done by PIRATE --> for GWAS kmer annotation
		##	"representative_sequences.faa" containing all gene families' representative sequence --> for eggnog-mapper

### --- ###


## 5) eggnog-mapper: https://github.com/eggnogdb/eggnog-mapper
## Program was run through the University of Oxford ARC computer cluster, in a personal conda environment

chdir='/dir/to/pirate_output'
OUTDIR="/dir/to/eggngo_output"

emapper.py -m diamond --itype proteins -i ${chdir}/representative_sequences.faa -o out --output_dir ${OUTDIR} --excel --cpu 8

### --- ###


## 6) RAxML: https://github.com/stamatak/standard-RAxML, and
## 7) ClonalFrameML: https://github.com/xavierdidelot/clonalframeml/wiki
## Program was run through the University of Oxford ARC computer cluster

module load RAxML/8.2.12-gompi-2020a-hybrid-avx2
module load ClonalFrameML/1.12-foss-2022a

infile="/dir/to/core_alignment.fasta" # core alignment from cgMLST scheme, generated by PubMLST Genome comparator

raxmlHPC -m GTRGAMMA -p 184029 -T 48 -N 5 -s ${infile} -n gwas_dataset_core.nwk
ClonalFrameML /dir/to/RAxML_output/RAxML_bestTree.gwas_dataset_core.nwk ${infile} gwas_dataset_CFML

### --- ###


## 8) NTHi unitigs: https://github.com/bacpop/unitig-counter
## Program was run through the University of Oxford ARC computer cluster, in a personal conda environment

INFILE="/dir/to/unitigs_input_file.txt" # 2 columns: "ID" for genome ID, "Path" for complete path to fasta files
OUTDIR="/dir/for/output"

unitig-counter -strains ${INFILE} -output ${OUTDIR} -nb-cores 16

### --- ###


## 9) Capsule region masking (1): 
## 	- LD Decay analysis: https://github.com/jeju2486/maskGWAS/tree/main and https://github.com/GELOG/plink
	## - This analysis was done separately for each capsule type, except for type c and d as there were too few genomes in PubMLST
##	- capsule + flanking region unitigs
## Pipeline was run through the University of Oxford ARC computer cluster

## 9.1) LD Decay analysis

module load BWA/0.7.17-GCCcore-11.2.0
module load SAMtools/1.16.1-GCC-11.3.0
module load BCFtools/1.14-GCC-11.2.0

rgenome="/dir/to/reference_genome.fasta" # NCBI accessions: NC_016809.1 (Hib), CP017811 (Hia), SRX6602169 (Hie), CP005967 (Hif)
bam_output="/dir/for/bam_output"
isolate_dir="/dir/to/fasta" # fasta files of capsulated H. Influenzae genome assemblies deposited in PubMLST
ld_output="/dir/for/final_output"
plink_dir="dir/to/plink_tools"

bwa index "$rgenome"
samtools faidx "$rgenome"

for f in $(cat ./type_b.txt); do # text file listing fasta file names of isolates within a specific capsule type
	bam_name=$f
	read_group="@RG\tID:$bam_name\tSM:$bam_name\tPL:ILLUMINA"

	if [ -e "$bam_output/${bam_name}.bam" ]; then
    echo "File ${bam_name}.bam already exists. Skipping."
  else
    echo "Processing $bam_name"
    bwa mem -R "$read_group" "$rgenome" "$isolate_dir/${f}.fasta" > "$bam_output/${bam_name}.sam"
    samtools view -Sb "$bam_output/${bam_name}.sam" > "$bam_output/${bam_name}.bam"
    rm "$bam_output/${bam_name}.sam"
  fi
done

samtools merge -r "$bam_output/merged.bam" "$bam_output"/*.bam # Merge BAM files while retaining read group information

samtools sort "$bam_output/merged.bam" -o "$bam_output/merged.sorted.bam" # Sort and index the merged BAM file
samtools index "$bam_output/merged.sorted.bam"

bcftools mpileup -Ou -f "$rgenome" "$bam_output/merged.sorted.bam" | # Variant calling using samtools and bcftools on the merged and sorted BAM file \
bcftools call -mv -Ob -o "$bam_output/variants.bcf"

bcftools view "$bam_output/variants.bcf" -o "$bam_output/variants.vcf"

ld_output="/data/zool-bactgenomics/hert6608/chapter3/hinf/mask_capsule/ld_output_wg_a"

total_snps=$(grep -vc "^#" "$bam_output/variants.vcf") # Count the number of SNPs (non-header lines)

target_snps=$((total_snps / 10)) # Calculate 1/10th of the total SNPs

grep "^#" "$bam_output/variants.vcf" > "$bam_output/variants_reduced.vcf" # Randomly select approximately 1/10th of the SNPs; Keep the VCF header

grep -v "^#" "$bam_output/variants.vcf" | shuf | head -n "$target_snps" >> "$bam_output/variants_reduced.vcf" # Randomly select SNPs and add them to the reduced VCF file

${plink_dir}/plink --double-id --threads 8 --allow-extra-chr --vcf "$bam_output/variants_reduced.vcf"  --make-bed --out temp
${plink_dir}/plink --double-id --allow-extra-chr --bfile temp --ld-window 200000 --threads 8 --r2 --ld-window-kb 2900 --ld-window-r2 0 --out "$ld_output/ld_output"

awk 'BEGIN {OFS="\t"} {print $1,$2,$3,$4,$5,$6,$7}' "$ld_output/ld_output.ld" > "$ld_output/ld_output_tab_delimited.ld"

rm temp*
rm "$ld_output/ld_output.ld"

awk 'BEGIN {srand()} NR==1 || (!/^($|[:space:]*#)/ && rand() <= 0.01) { print $0 }' "$ld_output/ld_output_tab_delimited.ld" > "$ld_output/ld_output_sampled.ld"

echo "Processing complete."

## Result: visual checks of LD analyses outputs --> LD decay at 5kb, therefore capsule region + 5kb flanking was masked from unitigs


## 9.2) generate unitigs from capsule region + flanking from ALL public capsulated genomes in PubMLST

INFILE="/dir/to/capsreg_input_file.txt" # 2 columns: "ID" for genome ID, "Path" for complete path to fasta files
OUTDIR="/dir/for/output_capsreg"

unitig-counter -strains ${INFILE} -output ${OUTDIR} -nb-cores 8

### --- ### Capsule region masking (2) is documented in gwas_code.py (In-house python script)


## 10) pyseer: https://pyseer.readthedocs.io/en/master/
## Program was run through the University of Oxford ARC computer cluster, in a personal conda environment

in_aln="/dir/to/core_genome_alignment.nwk" # core genome alignment tree reconstructed using RaXML and CFML
in_unitigs="/dir/to/unitigs_output/nthi_unitigs_output/unitigs_no_capsreg.txt" # use modified nthi unitigs resulted from step (3) in gwas_code.py
in_dm="/dir/to/distance_matrix.txt" # distance matrix from cgMLST scheme generated using PubMLST Genome Comparator
in_phenotype="dir/to/phenotype.txt" # contains 2 columns: "genome ID" and "phenotype" (1: invasive, 0: non-invasive)
in_clust="/dir/to/lincode_lineage_t800.txt" # contains 2 columns: "genome ID" and "lineage", which used cgLIN clusters at superlineage level (threshold: 800 allelic mismatches)
OUTDIR="/dir/to/pyseer_output"

python scripts/phylogeny_distance.py --lmm ${in_aln} > similarity.tsv

pyseer --lmm --phenotypes ${in_phenotype} --uncompressed \
	--kmers ${in_unitigs} --distances distance_matrix.txt \
	--similarity similarity.tsv \
	--lineage --lineage-clusters ${in_clust} \
	--lineage-file ${OUTDIR}/lineage_effect.out \
	--output-patterns ${OUTDIR}/kmers_pattern.txt \
	--cpu 16 > ${OUTDIR}/output_kmers.txt

python scripts/count_patterns.py ${OUTDIR}/kmers_pattern.txt # to define threshold

threshold="4.60E-08" # example threshold

cat <(head -1 output_kmers.txt) <(awk '$4<X {print $0}' output_kmers.txt) > significant_kmers.txt

## steps above were repeated 200x for each GWAS subset in accordance with Figure 4.1. in thesis
## all significant kmers were consolidated from all GWAS runs --> significant_kmers_summary.txt

in_ref="/dir/to/references.txt" 	# contains 3 columns: path to fasta, path to modified_gffs output from PIRATE, ref/draft genome
									# e.g. 	Haemophilus_influenzae_477.fna	Haemophilus_influenzae_477.gff	ref
									#		1.fasta	1.gff	draft
OUTDIR="/dir/to/annotation_summary"

annotate_hits_pyseer significant_kmers_summary.txt ${in_ref} ${OUTDIR}/annotated_kmers.txt
python scripts/summarise_annotations.py ${OUTDIR}/annotated_kmers.txt > ${OUTDIR}/gene_hits.txt

## extract kmers sequences from annotated_kmers.txt to map back to all isolates using Genome Comparator --> result: map_presence_absence.csv
## gene_hits.txt output was visualised as scatter plot and completed for functional annotation and COG information, as stored in Supplementary Table 4.5 of the thesis

### --- ###


